# Storage configuration for on-premises deployment
# This assumes you have a storage class available or uses local storage
#
# IMPORTANT: This is an example configuration. You MUST update:
#   - The path in PersistentVolume (line 33): Update to your actual storage path
#   - The node names in nodeAffinity (lines 41-42): Update with your GPU node names
#   - The storage capacity to match your available storage

---
# StorageClass for model cache (local NVMe or SSD recommended)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: neuronetes-model-cache
  labels:
    app.kubernetes.io/name: neuronetes
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Retain
---
# Example PersistentVolume for model cache
# IMPORTANT: Modify path and nodeAffinity for your environment
apiVersion: v1
kind: PersistentVolume
metadata:
  name: neuronetes-model-cache-pv
  labels:
    app.kubernetes.io/name: neuronetes
    type: local
spec:
  capacity:
    storage: 500Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: neuronetes-model-cache
  local:
    # TODO: Update this path to your actual model cache storage location
    path: /data/neuronetes/model-cache
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                # TODO: Update with your actual GPU node hostnames
                - gpu-node-1
                - gpu-node-2
---
# PersistentVolumeClaim for model cache
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: neuronetes-model-cache
  namespace: neuronetes-system
  labels:
    app.kubernetes.io/name: neuronetes
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: neuronetes-model-cache
  resources:
    requests:
      storage: 500Gi
---
# ConfigMap for on-premises configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: neuronetes-config
  namespace: neuronetes-system
  labels:
    app.kubernetes.io/name: neuronetes
data:
  # Model storage configuration
  model-storage-path: "/data/neuronetes/models"
  model-cache-path: "/data/neuronetes/model-cache"
  
  # GPU configuration
  gpu-topology-enabled: "true"
  gpu-mig-enabled: "false"
  
  # Network configuration
  internal-registry: ""  # Set to your internal registry if needed
  
  # Autoscaling configuration
  min-scale-delay: "30s"
  max-scale-delay: "5m"
